{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T07:20:53.693395Z","iopub.execute_input":"2021-12-22T07:20:53.694197Z","iopub.status.idle":"2021-12-22T07:20:53.736335Z","shell.execute_reply.started":"2021-12-22T07:20:53.694099Z","shell.execute_reply":"2021-12-22T07:20:53.735220Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"### Unzipping Dataset\nimport zipfile\n\nwith zipfile.ZipFile(\"../input/dogs-vs-cats/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \nwith zipfile.ZipFile(\"../input/dogs-vs-cats/test1.zip\",\"r\") as z:\n    z.extractall(\".\")","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:21:29.962196Z","iopub.execute_input":"2021-12-22T07:21:29.962575Z","iopub.status.idle":"2021-12-22T07:21:51.152984Z","shell.execute_reply.started":"2021-12-22T07:21:29.962534Z","shell.execute_reply":"2021-12-22T07:21:51.151999Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport random\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\nfrom torchvision.models import resnet50\n\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:22:02.569008Z","iopub.execute_input":"2021-12-22T07:22:02.569301Z","iopub.status.idle":"2021-12-22T07:22:05.784958Z","shell.execute_reply.started":"2021-12-22T07:22:02.569270Z","shell.execute_reply":"2021-12-22T07:22:05.783968Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"DIR_TRAIN = \"/kaggle/working/train/\"\nDIR_TEST = \"/kaggle/working/test1\"","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:22:23.256391Z","iopub.execute_input":"2021-12-22T07:22:23.257180Z","iopub.status.idle":"2021-12-22T07:22:23.265729Z","shell.execute_reply.started":"2021-12-22T07:22:23.257146Z","shell.execute_reply":"2021-12-22T07:22:23.264211Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"imgs = os.listdir(DIR_TRAIN) \ntest_imgs = os.listdir(DIR_TEST)\n\nprint(imgs[:5])\nprint(test_imgs[:5])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:22:35.095103Z","iopub.execute_input":"2021-12-22T07:22:35.095391Z","iopub.status.idle":"2021-12-22T07:22:35.128407Z","shell.execute_reply.started":"2021-12-22T07:22:35.095359Z","shell.execute_reply":"2021-12-22T07:22:35.127463Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class_to_int = {'dog' : 0,'cat' : 1}\nint_to_class = {0 : 'dog', 1 : 'cat'}","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:23:01.406577Z","iopub.execute_input":"2021-12-22T07:23:01.406868Z","iopub.status.idle":"2021-12-22T07:23:01.414208Z","shell.execute_reply.started":"2021-12-22T07:23:01.406837Z","shell.execute_reply":"2021-12-22T07:23:01.412838Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dogs_list = [img for img in imgs if img.split('.')[0] == 'dog']\ncats_list = [img for img in imgs if img.split('.')[0] == 'cat']\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:25:02.242790Z","iopub.execute_input":"2021-12-22T07:25:02.243108Z","iopub.status.idle":"2021-12-22T07:25:02.269197Z","shell.execute_reply.started":"2021-12-22T07:25:02.243077Z","shell.execute_reply":"2021-12-22T07:25:02.267752Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(\"No of Dogs images: \", len(dogs_list))\nprint(\"No of Cats images: \", len(cats_list))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:26:06.485618Z","iopub.execute_input":"2021-12-22T07:26:06.486433Z","iopub.status.idle":"2021-12-22T07:26:06.493119Z","shell.execute_reply.started":"2021-12-22T07:26:06.486396Z","shell.execute_reply":"2021-12-22T07:26:06.491939Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_train_transform():\n    return T.Compose([\n        T.RandomHorizontalFlip(p=0.5),\n        T.RandomRotation(15),\n        T.RandomCrop(204),\n        T.ToTensor(),\n        T.Normalize((0, 0, 0),(1, 1, 1))\n    ])\n    \ndef get_val_transform():\n    return T.Compose([\n        T.ToTensor(),\n        T.Normalize((0, 0, 0),(1, 1, 1))\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:26:35.661562Z","iopub.execute_input":"2021-12-22T07:26:35.661864Z","iopub.status.idle":"2021-12-22T07:26:35.669377Z","shell.execute_reply.started":"2021-12-22T07:26:35.661832Z","shell.execute_reply":"2021-12-22T07:26:35.668337Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CatDogDataset(Dataset):\n    \n    def __init__(self, imgs, class_to_int, mode = \"train\", transforms = None):\n        \n        super().__init__()\n        self.imgs = imgs\n        self.class_to_int = class_to_int\n        self.mode = mode\n        self.transforms = transforms\n        \n    def __getitem__(self, idx):\n        \n        image_name = self.imgs[idx]\n        \n        ### Reading, converting and normalizing image\n        #img = cv2.imread(DIR_TRAIN + image_name, cv2.IMREAD_COLOR)\n        #img = cv2.resize(img, (224,224))\n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n        #img /= 255.\n        img = Image.open(DIR_TRAIN + image_name)\n        img = img.resize((224, 224))\n        \n        if self.mode == \"train\" or self.mode == \"val\":\n        \n            ### Preparing class label\n            label = self.class_to_int[image_name.split(\".\")[0]]\n            label = torch.tensor(label, dtype = torch.float32)\n\n            ### Apply Transforms on image\n            img = self.transforms(img)\n\n            return img, label\n        \n        elif self.mode == \"test\":\n            \n            ### Apply Transforms on image\n            img = self.transforms(img)\n\n            return img\n            \n        \n    def __len__(self):\n        return len(self.imgs)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:27:05.819056Z","iopub.execute_input":"2021-12-22T07:27:05.819345Z","iopub.status.idle":"2021-12-22T07:27:05.830934Z","shell.execute_reply.started":"2021-12-22T07:27:05.819313Z","shell.execute_reply":"2021-12-22T07:27:05.829501Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_imgs, val_imgs = train_test_split(imgs, test_size = 0.25)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:27:19.584429Z","iopub.execute_input":"2021-12-22T07:27:19.584765Z","iopub.status.idle":"2021-12-22T07:27:19.607279Z","shell.execute_reply.started":"2021-12-22T07:27:19.584733Z","shell.execute_reply":"2021-12-22T07:27:19.606170Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset = CatDogDataset(train_imgs, class_to_int, mode = \"train\", transforms = get_train_transform())\nval_dataset = CatDogDataset(val_imgs, class_to_int, mode = \"val\", transforms = get_val_transform())\ntest_dataset = CatDogDataset(test_imgs, class_to_int, mode = \"test\", transforms = get_val_transform())\n\ntrain_data_loader = DataLoader(\n    dataset = train_dataset,\n    num_workers = 4,\n    batch_size = 16,\n    shuffle = True\n)\n\nval_data_loader = DataLoader(\n    dataset = val_dataset,\n    num_workers = 4,\n    batch_size = 16,\n    shuffle = True\n)\n\ntest_data_loader = DataLoader(\n    dataset = test_dataset,\n    num_workers = 4,\n    batch_size = 16,\n    shuffle = True\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:27:53.032830Z","iopub.execute_input":"2021-12-22T07:27:53.033148Z","iopub.status.idle":"2021-12-22T07:27:53.046540Z","shell.execute_reply.started":"2021-12-22T07:27:53.033116Z","shell.execute_reply":"2021-12-22T07:27:53.045191Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:28:22.318900Z","iopub.execute_input":"2021-12-22T07:28:22.319206Z","iopub.status.idle":"2021-12-22T07:28:22.328229Z","shell.execute_reply.started":"2021-12-22T07:28:22.319175Z","shell.execute_reply":"2021-12-22T07:28:22.327115Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"len(val_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:28:32.369269Z","iopub.execute_input":"2021-12-22T07:28:32.369594Z","iopub.status.idle":"2021-12-22T07:28:32.376094Z","shell.execute_reply.started":"2021-12-22T07:28:32.369562Z","shell.execute_reply":"2021-12-22T07:28:32.374961Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for images, labels in train_data_loader:\n    \n    fig, ax = plt.subplots(figsize = (10, 10))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(make_grid(images, 4).permute(1,2,0))\n    break\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:40:14.342979Z","iopub.execute_input":"2021-12-22T07:40:14.343293Z","iopub.status.idle":"2021-12-22T07:40:15.660070Z","shell.execute_reply.started":"2021-12-22T07:40:14.343258Z","shell.execute_reply":"2021-12-22T07:40:15.659073Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:40:47.181373Z","iopub.execute_input":"2021-12-22T07:40:47.181723Z","iopub.status.idle":"2021-12-22T07:40:47.235762Z","shell.execute_reply.started":"2021-12-22T07:40:47.181687Z","shell.execute_reply":"2021-12-22T07:40:47.234526Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:41:06.975848Z","iopub.execute_input":"2021-12-22T07:41:06.976148Z","iopub.status.idle":"2021-12-22T07:41:06.982283Z","shell.execute_reply.started":"2021-12-22T07:41:06.976116Z","shell.execute_reply":"2021-12-22T07:41:06.980755Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:41:12.414704Z","iopub.execute_input":"2021-12-22T07:41:12.415030Z","iopub.status.idle":"2021-12-22T07:41:12.421501Z","shell.execute_reply.started":"2021-12-22T07:41:12.414989Z","shell.execute_reply":"2021-12-22T07:41:12.420521Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def accuracy(preds, trues):\n    \n    ### Converting preds to 0 or 1\n    preds = [1 if preds[i] >= 0.5 else 0 for i in range(len(preds))]\n    \n    ### Calculating accuracy by comparing predictions with true labels\n    acc = [1 if preds[i] == trues[i] else 0 for i in range(len(preds))]\n    \n    ### Summing over all correct predictions\n    acc = np.sum(acc) / len(preds)\n    \n    return (acc * 100)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:41:30.886876Z","iopub.execute_input":"2021-12-22T07:41:30.887203Z","iopub.status.idle":"2021-12-22T07:41:30.894413Z","shell.execute_reply.started":"2021-12-22T07:41:30.887169Z","shell.execute_reply":"2021-12-22T07:41:30.893024Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(train_data_loader):\n    \n    ### Local Parameters\n    epoch_loss = []\n    epoch_acc = []\n    start_time = time.time()\n    \n    ###Iterating over data loader\n    for images, labels in train_data_loader:\n        \n        #Loading images and labels to device\n        images = images.to(device)\n        labels = labels.to(device)\n        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n        \n        #Reseting Gradients\n        optimizer.zero_grad()\n        \n        #Forward\n        preds = model(images)\n        \n        #Calculating Loss\n        _loss = criterion(preds, labels)\n        loss = _loss.item()\n        epoch_loss.append(loss)\n        \n        #Calculating Accuracy\n        acc = accuracy(preds, labels)\n        epoch_acc.append(acc)\n        \n        #Backward\n        _loss.backward()\n        optimizer.step()\n    \n    ###Overall Epoch Results\n    end_time = time.time()\n    total_time = end_time - start_time\n    \n    ###Acc and Loss\n    epoch_loss = np.mean(epoch_loss)\n    epoch_acc = np.mean(epoch_acc)\n    \n    ###Storing results to logs\n    train_logs[\"loss\"].append(epoch_loss)\n    train_logs[\"accuracy\"].append(epoch_acc)\n    train_logs[\"time\"].append(total_time)\n        \n    return epoch_loss, epoch_acc, total_time\n        ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:43:09.122268Z","iopub.execute_input":"2021-12-22T07:43:09.122586Z","iopub.status.idle":"2021-12-22T07:43:09.133606Z","shell.execute_reply.started":"2021-12-22T07:43:09.122552Z","shell.execute_reply":"2021-12-22T07:43:09.132036Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def val_one_epoch(val_data_loader, best_val_acc):\n    \n    ### Local Parameters\n    epoch_loss = []\n    epoch_acc = []\n    start_time = time.time()\n    \n    ###Iterating over data loader\n    for images, labels in val_data_loader:\n        \n        #Loading images and labels to device\n        images = images.to(device)\n        labels = labels.to(device)\n        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n        \n        #Forward\n        preds = model(images)\n        \n        #Calculating Loss\n        _loss = criterion(preds, labels)\n        loss = _loss.item()\n        epoch_loss.append(loss)\n        \n        #Calculating Accuracy\n        acc = accuracy(preds, labels)\n        epoch_acc.append(acc)\n    \n    ###Overall Epoch Results\n    end_time = time.time()\n    total_time = end_time - start_time\n    \n    ###Acc and Loss\n    epoch_loss = np.mean(epoch_loss)\n    epoch_acc = np.mean(epoch_acc)\n    \n    ###Storing results to logs\n    val_logs[\"loss\"].append(epoch_loss)\n    val_logs[\"accuracy\"].append(epoch_acc)\n    val_logs[\"time\"].append(total_time)\n    \n    ###Saving best model\n    if epoch_acc > best_val_acc:\n        best_val_acc = epoch_acc\n        torch.save(model.state_dict(),\"resnet50_best.pth\")\n        \n    return epoch_loss, epoch_acc, total_time, best_val_acc\n        ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:43:32.483095Z","iopub.execute_input":"2021-12-22T07:43:32.483384Z","iopub.status.idle":"2021-12-22T07:43:32.493736Z","shell.execute_reply.started":"2021-12-22T07:43:32.483353Z","shell.execute_reply":"2021-12-22T07:43:32.492350Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = resnet50(pretrained = True)\n\n# Modifying Head - classifier\n\nmodel.fc = nn.Sequential(\n    nn.Linear(2048, 1, bias = True),\n    nn.Sigmoid()\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:44:18.412869Z","iopub.execute_input":"2021-12-22T07:44:18.413194Z","iopub.status.idle":"2021-12-22T07:44:23.150669Z","shell.execute_reply.started":"2021-12-22T07:44:18.413161Z","shell.execute_reply":"2021-12-22T07:44:23.149694Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n\n# Learning Rate Scheduler\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n\n#Loss Function\ncriterion = nn.BCELoss()\n\n# Logs - Helpful for plotting after training finishes\ntrain_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\nval_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n\n# Loading model to device\nmodel.to(device)\n\n# No of epochs \nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:44:52.453095Z","iopub.execute_input":"2021-12-22T07:44:52.453390Z","iopub.status.idle":"2021-12-22T07:44:56.511776Z","shell.execute_reply.started":"2021-12-22T07:44:52.453357Z","shell.execute_reply":"2021-12-22T07:44:56.510756Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"best_val_acc = 0\nfor epoch in range(epochs):\n    \n    ###Training\n    loss, acc, _time = train_one_epoch(train_data_loader)\n    \n    #Print Epoch Details\n    print(\"\\nTraining\")\n    print(\"Epoch {}\".format(epoch+1))\n    print(\"Loss : {}\".format(round(loss, 4)))\n    print(\"Acc : {}\".format(round(acc, 4)))\n    print(\"Time : {}\".format(round(_time, 4)))\n    \n    ###Validation\n    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, best_val_acc)\n    \n    #Print Epoch Details\n    print(\"\\nValidating\")\n    print(\"Epoch {}\".format(epoch+1))\n    print(\"Loss : {}\".format(round(loss, 4)))\n    print(\"Acc : {}\".format(round(acc, 4)))\n    print(\"Time : {}\".format(round(_time, 4)))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T07:45:14.487118Z","iopub.execute_input":"2021-12-22T07:45:14.487419Z","iopub.status.idle":"2021-12-22T08:20:38.315939Z","shell.execute_reply.started":"2021-12-22T07:45:14.487386Z","shell.execute_reply":"2021-12-22T08:20:38.314547Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"### Plotting Results\n\n#Loss\nfig = plt.figure(figsize = (20, 20))\nplt.title(\"Loss\")\nplt.plot(np.arange(1, 11, 1), train_logs[\"loss\"], color = 'blue')\nplt.plot(np.arange(1, 11, 1), val_logs[\"loss\"], color = 'yellow')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()\n\n#Accuracy\nfig = plt.figure(figsize = (20, 20))\nplt.title(\"Accuracy\")\nplt.plot(np.arange(1, 11, 1), train_logs[\"accuracy\"], color = 'blue')\nplt.plot(np.arange(1, 11, 1), val_logs[\"accuracy\"], color = 'yellow')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T08:23:38.727602Z","iopub.execute_input":"2021-12-22T08:23:38.727900Z","iopub.status.idle":"2021-12-22T08:23:39.360906Z","shell.execute_reply.started":"2021-12-22T08:23:38.727868Z","shell.execute_reply":"2021-12-22T08:23:39.359901Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}